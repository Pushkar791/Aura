# ğŸš€ AURA Web Application - Quick Start Guide

## ğŸ“‹ What You Get

A professional web interface with **2 modes**:

1. **ğŸ¥ Real-Time Detection** - Live webcam feed with safety equipment detection
2. **ğŸ“Š Dataset Evaluation** - Process test images and display accuracy metrics

---

## âš¡ Quick Start

### 1. Install Flask (if not already installed)
```bash
pip install flask
```

### 2. Start the Server
```bash
python app.py
```

### 3. Open Browser
Navigate to: **http://localhost:5000**

---

## ğŸ¯ Features

### Real-Time Detection Mode
âœ… Live webcam/camera feed  
âœ… Real-time object detection  
âœ… FPS counter  
âœ… Detection confidence overlay  
âœ… Color-coded bounding boxes  
âœ… System information display  

### Dataset Evaluation Mode
âœ… One-click evaluation  
âœ… Progress bar with live updates  
âœ… Comprehensive metrics (Accuracy, Precision, Recall, F1)  
âœ… Per-class performance breakdown  
âœ… Professional results display  
âœ… Interactive UI  

---

## ğŸ¨ UI Highlights

- **Modern gradient background** - Purple/blue gradient
- **Glass morphism design** - Frosted glass effect cards
- **Responsive layout** - Works on all screen sizes
- **Smooth animations** - Professional transitions
- **Color-coded detections** - Each class has unique color
- **Real-time metrics** - Live FPS, inference time, detections

---

## ğŸ”§ Configuration

Edit `app.py` to customize:

```python
MODEL_PATH = "runs/safety_equipment/weights/best.pt"  # Your model
TEST_DATA_PATH = r"C:\Users\...\test"  # Test dataset path
CONFIDENCE_THRESHOLD = 0.20  # Detection threshold
```

---

## ğŸ“Š What Judges Will See

### Mode 1: Real-Time Detection
1. Click "Real-Time Detection" button
2. **Live camera feed** with colored bounding boxes
3. **Detection stats** showing FPS and inference time
4. **Color legend** for each safety equipment class
5. **System info** showing GPU, device, confidence

### Mode 2: Dataset Evaluation
1. Click "Dataset Evaluation" button
2. Click "Start Evaluation" - shows **progress bar**
3. After completion, displays:
   - **Big metric cards**: Accuracy, Precision, Recall, F1
   - **Stats grid**: Images processed, detections, FPS
   - **Performance table**: Per-class breakdown
   - All in **real percentages** (e.g., 31.4%, 67.4%)

---

## ğŸ† Hackathon Demo Tips

### For Judges:

1. **Start with Real-Time Mode**
   - Show live detection working
   - Point out the FPS (21 FPS)
   - Show different objects being detected

2. **Switch to Evaluation Mode**
   - Click "Start Evaluation"
   - Let them see the progress bar (impressive!)
   - Results appear automatically

3. **Highlight Key Metrics**
   - Point to big numbers (Accuracy, Precision, Recall)
   - Show per-class performance table
   - Mention GPU acceleration

### Talking Points:
- "Real-time detection at 21 FPS on RTX 3050"
- "Trained on 1,000+ images across 7 equipment types"
- "Achieves X% accuracy with Y% precision"
- "Handles varying lighting and clutter conditions"
- "Production-ready web interface"

---

## ğŸ”¥ Making It Even Better

### Before the Hackathon:

1. **Train improved model** (100 epochs)
   ```bash
   python train_improved.py
   ```
   
2. **Update app.py** with new model path:
   ```python
   MODEL_PATH = "runs/train/improved_model/weights/best.pt"
   ```

3. **Test everything**:
   ```bash
   python app.py
   ```
   Open browser and test both modes

### Expected Results After Improved Training:
- Accuracy: **50-60%** (vs 31% now)
- Precision: **75-85%** (vs 67% now)  
- Recall: **60-70%** (vs 37% now)
- Much more impressive for judges!

---

## ğŸ› Troubleshooting

### Camera not working?
- Check if another app is using camera
- Try different camera ID in `app.py`: `cv2.VideoCapture(1)`

### Model not found?
- Verify MODEL_PATH in `app.py`
- Check if model file exists

### Port 5000 already in use?
- Change port in `app.py`: `app.run(port=5001)`

### Slow performance?
- Make sure GPU is detected
- Check CUDA installation
- Reduce batch size if needed

---

## ğŸ“ File Structure

```
AURA/
â”œâ”€â”€ app.py                          # Flask backend
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                  # Frontend UI
â”œâ”€â”€ runs/
â”‚   â””â”€â”€ safety_equipment/
â”‚       â””â”€â”€ weights/
â”‚           â””â”€â”€ best.pt             # Your model
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.yaml                # Dataset config
â””â”€â”€ test dataset/                   # Test images
```

---

## ğŸ¬ Demo Sequence

### Perfect 3-Minute Demo:

**Minute 1: Introduction**
- "AURA is an AI-powered safety equipment detection system"
- "It uses YOLOv8 trained on custom dataset"
- "Let me show you the web interface"

**Minute 2: Real-Time Detection**
- Switch to Real-Time mode
- Show camera detecting objects
- Point out FPS, accuracy, colored boxes
- "Running at 21 FPS on consumer GPU"

**Minute 3: Evaluation Results**
- Switch to Dataset Evaluation
- Click Start Evaluation
- Show progress bar
- Results appear: "31% accuracy, 67% precision"
- Show per-class table
- **"With improved training (100 epochs), we expect 50-60% accuracy"**

**Closing:**
- "Production-ready, real-time, GPU-accelerated"
- "Thank you!"

---

## ğŸ’¡ Pro Tips

1. **Practice the demo** - Know where to click
2. **Have backup screenshots** - In case of technical issues
3. **Explain the metrics** - Accuracy, Precision, Recall
4. **Show the code** - If judges ask, show app.py
5. **Be honest** - Explain current limitations and future improvements

---

## ğŸŒŸ What Makes This Special

âœ¨ **Dual-mode interface** - Both live and evaluation  
âœ¨ **Professional UI** - Not a basic terminal app  
âœ¨ **Real metrics** - Actual performance numbers  
âœ¨ **GPU-accelerated** - Fast, production-ready  
âœ¨ **Easy to use** - One click to evaluate  
âœ¨ **Impressive visuals** - Judges will love it  

---

## ğŸš€ Run It Now!

```bash
python app.py
```

Then open: **http://localhost:5000**

**Good luck with your hackathon! ğŸ†**
